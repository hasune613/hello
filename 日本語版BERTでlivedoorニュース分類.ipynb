{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "日本語版BERTでlivedoorニュース分類.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPslodcLceqbW+2ljtqL8+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bbbc86b271841c0ae2b1d9e41566097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f40a1b0e09e4389bfd7595d815b06b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9d55dc44ecd4d08adeda2e554fadef4",
              "IPY_MODEL_8bcb2d1e0bf34bdb8bc52dec551e98b4",
              "IPY_MODEL_06322aaf7e774e5d85f361aa252aa2d7"
            ]
          }
        },
        "4f40a1b0e09e4389bfd7595d815b06b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9d55dc44ecd4d08adeda2e554fadef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6559cefc6298460e98f5b72920f79a66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_642efdbb952046c9b7ba9f17affa3a71"
          }
        },
        "8bcb2d1e0bf34bdb8bc52dec551e98b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8068ae8a3a4b4e96ac0e9fc8953021f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cc246adf4ff4b4b9739272f1c8ed48d"
          }
        },
        "06322aaf7e774e5d85f361aa252aa2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68bb7e5c1d824e7fbe0798bc17c2b1ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:00&lt;00:00, 1.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_507f75bca2c943b58c93f9e494a8655a"
          }
        },
        "6559cefc6298460e98f5b72920f79a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "642efdbb952046c9b7ba9f17affa3a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8068ae8a3a4b4e96ac0e9fc8953021f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cc246adf4ff4b4b9739272f1c8ed48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68bb7e5c1d824e7fbe0798bc17c2b1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "507f75bca2c943b58c93f9e494a8655a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasune613/hello-world/blob/main/%E6%97%A5%E6%9C%AC%E8%AA%9E%E7%89%88BERT%E3%81%A7livedoor%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%B9%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMu7b630Yvun",
        "outputId": "332a4b01-b71c-4c97-a0dc-cc53ef03555c"
      },
      "source": [
        "# Livedoorニュースのファイルをダウンロード\n",
        "! wget \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-09 00:28:40--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  5.51MB/s    in 1.5s    \n",
            "\n",
            "2021-09-09 00:28:42 (5.51 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtU9zYFkYwYc",
        "outputId": "0f3df47e-9bf0-4892-d641-be8794c61613"
      },
      "source": [
        "# ファイルを解凍し、カテゴリー数と内容を確認\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# 解凍\n",
        "tar = tarfile.open(\"ldcc-20140209.tar.gz\", \"r:gz\")\n",
        "tar.extractall(\"./data/livedoor/\")\n",
        "tar.close()\n",
        "\n",
        "# フォルダのファイルとディレクトリを確認\n",
        "files_folders = [name for name in os.listdir(\"./data/livedoor/text/\")]\n",
        "print(files_folders)\n",
        "\n",
        "# カテゴリーのフォルダのみを抽出\n",
        "categories = [name for name in os.listdir(\n",
        "    \"./data/livedoor/text/\") if os.path.isdir(\"./data/livedoor/text/\"+name)]\n",
        "\n",
        "print(\"カテゴリー数:\", len(categories))\n",
        "print(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CHANGES.txt', 'peachy', 'smax', 'movie-enter', 'it-life-hack', 'sports-watch', 'dokujo-tsushin', 'README.txt', 'kaden-channel', 'livedoor-homme', 'topic-news']\n",
            "カテゴリー数: 9\n",
            "['peachy', 'smax', 'movie-enter', 'it-life-hack', 'sports-watch', 'dokujo-tsushin', 'kaden-channel', 'livedoor-homme', 'topic-news']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5eIK7DEuWY0"
      },
      "source": [
        "# !ls ./data/livedoor/text/peachy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFXv9XlCr7YF",
        "outputId": "6dd28b1d-15f5-4ade-d38d-dacf240a2f07"
      },
      "source": [
        "#  ファイルの中身を確認してみる\n",
        "file_name = \"./data/livedoor/text/movie-enter/movie-enter-6255260.txt\"\n",
        "\n",
        "with open(file_name) as text_file:\n",
        "    text = text_file.readlines()\n",
        "    print(\"0：\", text[0])  # URL情報\n",
        "    print(\"1：\", text[1])  # タイムスタンプ\n",
        "    print(\"2：\", text[2])  # タイトル\n",
        "    print(\"3：\", text[3])  # 本文\n",
        "\n",
        "    # 今回は4要素目には本文は伸びていないが、4要素目以降に本文がある場合もある\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0： http://news.livedoor.com/article/detail/6255260/\n",
            "\n",
            "1： 2012-02-07T09:00:00+0900\n",
            "\n",
            "2： 新しいヴァンパイアが誕生！　ジョニデ主演『ダーク・シャドウ』の公開日が決定\n",
            "\n",
            "3： 　こんなヴァンパイアは見たことがない！　ジョニー・デップとティム・バートン監督がタッグを組んだ映画『ダーク・シャドウズ（原題）』の邦題が『ダーク・シャドウ』に決定。日本公開日が5月19日に決まった。さらに、ジョニー・デップ演じるヴァンパイアの写真が公開された。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTpNBOQtNmQ"
      },
      "source": [
        "## 本文を取得する前処理関数を定義\n",
        "\n",
        "\n",
        "def extract_main_txt(file_name):\n",
        "    with open(file_name) as text_file:\n",
        "        # 今回はタイトル行は外したいので、3要素目以降の本文のみ使用\n",
        "        text = text_file.readlines()[3:]\n",
        "\n",
        "        # 3要素目以降にも本文が入っている場合があるので、リストにして、後で結合させる\n",
        "        text = [sentence.strip() for sentence in text]  # 空白文字(スペースやタブ、改行)の削除\n",
        "        text = list(filter(lambda line: line != '', text))\n",
        "        text = ''.join(text)\n",
        "        text = text.translate(str.maketrans(\n",
        "            {'\\n': '', '\\t': '', '\\r': '', '\\u3000': ''}))  # 改行やタブ、全角スペースを消す\n",
        "        return text\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCPklfhyznu7"
      },
      "source": [
        "# リストに前処理した本文と、カテゴリーのラベルを追加していく\n",
        "import glob\n",
        "\n",
        "list_text = []\n",
        "list_label = []\n",
        "\n",
        "for cat in categories:\n",
        "    text_files = glob.glob(os.path.join(\"./data/livedoor/text\", cat, \"*.txt\"))\n",
        "\n",
        "    # 前処理extract_main_txtを実施して本文を取得\n",
        "    body = [extract_main_txt(text_file) for text_file in text_files]\n",
        "\n",
        "    label = [cat] * len(body)  # bodyの数文だけカテゴリー名のラベルのリストを作成\n",
        "\n",
        "    list_text.extend(body)  # appendが要素を追加するのに対して、extendはリストごと追加する\n",
        "    list_label.extend(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71RmcZzdznrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db63bf2-f569-4415-9bd2-f0af66dbcff0"
      },
      "source": [
        "## 0番目の文章とラベルを確認\n",
        "print(list_text[0])\n",
        "print(list_label[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "「仕事」「プライベート」「恋愛」・・・がんばってる女の子ほど悩みの種やストレスの元は、多いもの。ストレスがたまると、カサカサ、ポツポツ・・・なんてことも。「ストレス」と「肌」の関係は、とても深く、密接なものです。毎日の暮らしのわずかな変化に、知らず知らずのうちに肌も不安定になってしまいます。「何かにとりつかれたように、最低な一日を過ごしたことがあります。」そう話してくれたのは、仕事のできるステキ女子を目指すA子さん（会社員・29歳）。「仕事で取引先と問題が発生。上司にこっぴどく叱られ、対応に追われなかなか帰れず、彼との約束の時間に遅れたら、彼がお怒りモード。自分もイライラしてしまって、結局はケンカしてデートにならず・・・。がんばってるつもりが空回り。一体何やってるんだろうと思いながらの帰りの電車、今度は酔っ払いに絡まれ、怖い思いをしたことがあります。もうそんな夜は、何も気力が残らず化粧を落とすだけで精一杯。ベッドへ直行して、眠るだけ。ひたすら癒されたい・・・と思いながら。（笑）」マンガやドラマみたいですが、誰もがなんで！？というぐらいに最低最悪な一日を過ごしたことはあるのではないでしょうか。そんなストレスがたまる一日もあなたの言葉や態度の一つで、回避できることもあるかもしれません。大人の女子力を身につけて一歩上のステキ女子を目指してはいかがでしょうか。まずは、あなたの女子力を診断！「大人の女子力診断」はコチラからそれでもやっぱりがんばる女の子には、肌も心も癒す時間が必要。夜寝る前にお肌のケアをする瞬間、お風呂でくつろぐ瞬間、恋人との電話など・・・皆さんの癒しのひとときは、何ですか？肌も心も傷ついた女性を癒す“ビューネくん”のCMでおなじみの「薬用 ビューネ」は、ストレスで不安定になりがちな肌をやさしく癒してくれます。大人の肌はとっても繊細。「薬用 ビューネ」は、「温泉」、「海」、「植物」の３つの自然のチカラを活かしたＳＰＡエッセンスを配合することで、肌荒れ・ニキビになりやすい肌のコンディションを整えて、ストレスに負けないすこやかなスベスベ肌へと導きます。ツイてる日もツイてない日も「ビューネ」で肌を癒しませんか？「Peachy」では、「“ビューネくん”に癒されたくなる瞬間」をTwitterで募集。ツイートいただいた方の中から抽選で5名様に「薬用 ビューネ」をプレゼントいたします。「ビューネくんに癒されたくなる瞬間は？」Twitterでツイートして、応募しよう！「ビューネくんに癒されたくなる瞬間」を『ツイートする』ボタンからツイートいただいた方の中から抽選で5名様に、「薬用 ビューネ」をプレゼントいたします！ぜひ、ふるってご応募ください！■賞品・応募数『薬用 ビューネ』 ／ 5名様■プレゼント応募期間2011年8月4日（木）〜2011年8月17日（水）■応募方法■【STEP1】 TwitterでPeachy公式アカウント（@ld_girls）をフォロー。【STEP2】 「ビューネくんに癒されたくなる瞬間」を『ツイートする』ボタンからツイート！例）・仕事で取引先と上司からＷパンチ。これまでにないぐらい怒られた。・久しぶりの家族団らんで、結局大ゲンカしてしまった。・彼氏とケンカした・・・。■当選発表・発送■・厳正なる抽選の上、当選された方にはツイッターのダイレクトメッセージにてお知らせします。・当選告知までにフォロー解除された場合は、ご応募が無効となりますので、ご注意ください。・なお、賞品の発送は8月下旬頃を予定しております。※下記のように赤枠部分に「ビューネくんに癒されたくなる瞬間」をツイートしてください。※※本キャンペーンは、終了しました。※■関連情報『薬用 ビューネ』160mL6,000円（税込6,300円）日本メナード化粧品株式会社詳細はこちら\n",
            "peachy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR0JXXNDzngo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "aa99726d-af4b-415c-f678-bfd3af7a596d"
      },
      "source": [
        "# pandasのDataFrameにする\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'text': list_text, 'label': list_label})\n",
        "\n",
        "# 大きさを確認しておく（7,376文章が存在）\n",
        "print(df.shape)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7376, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>「仕事」「プライベート」「恋愛」・・・がんばってる女の子ほど悩みの種やストレスの元は、多いも...</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>厳しい夏もようやく終わりに近づいてきましたが、猛暑や紫外線によるダメージがたまり、身体やお肌...</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>「占い」は、いつだって女子の強い味方。雑誌やネットで新しい「○○占い」を見かけるたびに、試し...</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>男心を捉えるには“胃袋を掴むこと”は、昔から言われている必殺方法。確かに、周りの男子から聞く...</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>みなさんは、小さな頃からきちんと歯を磨いていましたか？ 面倒でイヤイヤやっていた人も多いので...</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   label\n",
              "0  「仕事」「プライベート」「恋愛」・・・がんばってる女の子ほど悩みの種やストレスの元は、多いも...  peachy\n",
              "1  厳しい夏もようやく終わりに近づいてきましたが、猛暑や紫外線によるダメージがたまり、身体やお肌...  peachy\n",
              "2  「占い」は、いつだって女子の強い味方。雑誌やネットで新しい「○○占い」を見かけるたびに、試し...  peachy\n",
              "3  男心を捉えるには“胃袋を掴むこと”は、昔から言われている必殺方法。確かに、周りの男子から聞く...  peachy\n",
              "4  みなさんは、小さな頃からきちんと歯を磨いていましたか？ 面倒でイヤイヤやっていた人も多いので...  peachy"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIdJCH9czndQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "612c2930-8b5e-4f08-fd8e-4408e380a862"
      },
      "source": [
        "\n",
        "\n",
        "# カテゴリーの辞書を作成\n",
        "dic_id2cat = dict(zip(list(range(len(categories))), categories))\n",
        "dic_cat2id = dict(zip(categories, list(range(len(categories)))))\n",
        "\n",
        "print(dic_id2cat)\n",
        "print(dic_cat2id)\n",
        "\n",
        "# DataFrameにカテゴリーindexの列を作成\n",
        "df[\"label_index\"] = df[\"label\"].map(dic_cat2id)\n",
        "df.head()\n",
        "\n",
        "# label列を消去し、text, indexの順番にする\n",
        "df = df.loc[:, [\"text\", \"label_index\"]]\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'peachy', 1: 'smax', 2: 'movie-enter', 3: 'it-life-hack', 4: 'sports-watch', 5: 'dokujo-tsushin', 6: 'kaden-channel', 7: 'livedoor-homme', 8: 'topic-news'}\n",
            "{'peachy': 0, 'smax': 1, 'movie-enter': 2, 'it-life-hack': 3, 'sports-watch': 4, 'dokujo-tsushin': 5, 'kaden-channel': 6, 'livedoor-homme': 7, 'topic-news': 8}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>「仕事」「プライベート」「恋愛」・・・がんばってる女の子ほど悩みの種やストレスの元は、多いも...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>厳しい夏もようやく終わりに近づいてきましたが、猛暑や紫外線によるダメージがたまり、身体やお肌...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>「占い」は、いつだって女子の強い味方。雑誌やネットで新しい「○○占い」を見かけるたびに、試し...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>男心を捉えるには“胃袋を掴むこと”は、昔から言われている必殺方法。確かに、周りの男子から聞く...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>みなさんは、小さな頃からきちんと歯を磨いていましたか？ 面倒でイヤイヤやっていた人も多いので...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label_index\n",
              "0  「仕事」「プライベート」「恋愛」・・・がんばってる女の子ほど悩みの種やストレスの元は、多いも...            0\n",
              "1  厳しい夏もようやく終わりに近づいてきましたが、猛暑や紫外線によるダメージがたまり、身体やお肌...            0\n",
              "2  「占い」は、いつだって女子の強い味方。雑誌やネットで新しい「○○占い」を見かけるたびに、試し...            0\n",
              "3  男心を捉えるには“胃袋を掴むこと”は、昔から言われている必殺方法。確かに、周りの男子から聞く...            0\n",
              "4  みなさんは、小さな頃からきちんと歯を磨いていましたか？ 面倒でイヤイヤやっていた人も多いので...            0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrGz954wznZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a6a16e74-cedc-4e62-bae3-3a093a4262f3"
      },
      "source": [
        "# 順番をシャッフルする\n",
        "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“幸せ”って、何だろう？30代になり、子供の頃からの友達はほとんど結婚、子供を産み、専業主婦...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2月も既に後半。北日本ではまだ大雪が続いているが、沖縄では25度と早くも夏日になったとか。花...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012年の幕開けと同時に恒例の冬のセールもスタート。早速セールに出かけて「昨年から狙ってい...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12日放送、日本テレビ「NEWS ZERO」では、「ドイツ香川を独占直撃 移籍報道の真相は」...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label_index\n",
              "0  “幸せ”って、何だろう？30代になり、子供の頃からの友達はほとんど結婚、子供を産み、専業主婦...            5\n",
              "1  2月も既に後半。北日本ではまだ大雪が続いているが、沖縄では25度と早くも夏日になったとか。花...            6\n",
              "2  先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...            3\n",
              "3  2012年の幕開けと同時に恒例の冬のセールもスタート。早速セールに出かけて「昨年から狙ってい...            5\n",
              "4  12日放送、日本テレビ「NEWS ZERO」では、「ドイツ香川を独占直撃 移籍報道の真相は」...            4"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cG85xwhznWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400eff86-522a-41f5-a08b-a9e63edb85f7"
      },
      "source": [
        "dic_id2cat\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'peachy',\n",
              " 1: 'smax',\n",
              " 2: 'movie-enter',\n",
              " 3: 'it-life-hack',\n",
              " 4: 'sports-watch',\n",
              " 5: 'dokujo-tsushin',\n",
              " 6: 'kaden-channel',\n",
              " 7: 'livedoor-homme',\n",
              " 8: 'topic-news'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLmp5adYbf_8",
        "outputId": "c2bfa925-f231-4b20-b308-84fd5c8dd266"
      },
      "source": [
        "dic_cat2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dokujo-tsushin': 5,\n",
              " 'it-life-hack': 3,\n",
              " 'kaden-channel': 6,\n",
              " 'livedoor-homme': 7,\n",
              " 'movie-enter': 2,\n",
              " 'peachy': 0,\n",
              " 'smax': 1,\n",
              " 'sports-watch': 4,\n",
              " 'topic-news': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIF4TJXmbpqQ",
        "outputId": "5c03250b-8b9f-481e-b96a-440f1c960578"
      },
      "source": [
        "# tsvファイルで保存する\n",
        "\n",
        "# 全体の2割の文章数\n",
        "len_0_2 = len(df) // 5\n",
        "\n",
        "# 前から2割をテストデータとする\n",
        "df[:len_0_2].to_csv(\"./test.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[:len_0_2].shape)\n",
        "\n",
        "# 前2割からを訓練&検証データとする\n",
        "df[len_0_2:].to_csv(\"./train_eval.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[len_0_2:].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1475, 2)\n",
            "(5901, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_GZ4O8acRCf"
      },
      "source": [
        "# tsvファイルをダウンロードしたい場合\n",
        "from google.colab import files\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（4MB）\n",
        "# files.download(\"./test.tsv\")\n",
        "\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（18MB）\n",
        "# files.download(\"./train_eval.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iL0xKDu7E6Z"
      },
      "source": [
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make surl xz-utils file -y\n",
        "!pip install mecab-python3==0.996.5\n",
        "\n",
        "!pip install transformers==2.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-M1qMxfGfzk",
        "outputId": "f5854b8a-e81b-4b1a-873a-7936eb94d9c7"
      },
      "source": [
        "! pip install -q unidic-lite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 47.4 MB 39 kB/s \n",
            "\u001b[?25h  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFew8noCEmcv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5bbbc86b271841c0ae2b1d9e41566097",
            "4f40a1b0e09e4389bfd7595d815b06b8",
            "c9d55dc44ecd4d08adeda2e554fadef4",
            "8bcb2d1e0bf34bdb8bc52dec551e98b4",
            "06322aaf7e774e5d85f361aa252aa2d7",
            "6559cefc6298460e98f5b72920f79a66",
            "642efdbb952046c9b7ba9f17affa3a71",
            "8068ae8a3a4b4e96ac0e9fc8953021f8",
            "3cc246adf4ff4b4b9739272f1c8ed48d",
            "68bb7e5c1d824e7fbe0798bc17c2b1ad",
            "507f75bca2c943b58c93f9e494a8655a"
          ]
        },
        "outputId": "3e28b61a-3c97-45b1-a4ca-4a83f34c04e6"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "import torchtext#  torchtextを使用\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "# 日本語BERTの分かち書き用tokenizer\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(\n",
        "    'bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bbbc86b271841c0ae2b1d9e41566097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbN7hADQEmY5"
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義\n",
        "max_length = 512  # 東北大学_日本語版の最大の単語数（サブワード数）は512\n",
        "\n",
        "\n",
        "def tokenizer_512(input_text):\n",
        "    \"\"\"torchtextのtokenizerとして扱えるように、512単語のpytorchでのencodeを定義。[0]を指定し忘れないように\"\"\"\n",
        "    return tokenizer.encode(input_text, max_length=512, return_tensors='pt')[0]\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer_512, use_vocab=False, lower=False,\n",
        "                            include_lengths=True, batch_first=True, fix_length=max_length, pad_token=0)\n",
        "# 注意：tokenize=tokenizer.encodeと、.encodeをつけます。padding[PAD]のindexが0なので、0を指定します。\n",
        "\n",
        "LABEL =data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を用意するかどうか\n",
        "# fix_length：全部の文章をfix_lengthと同じ長さになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx9YyGE1MP2q"
      },
      "source": [
        "# 各tsvファイルを読み込み、分かち書きをしてdatasetにします\n",
        "# 少し時間がかかります\n",
        "# train_eval：5901個、test：1475個\n",
        "dataset_train_eval, dataset_test = data.TabularDataset.splits(\n",
        "    path='./', train='train_eval.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bz84UxXEmV-"
      },
      "source": [
        "dataset_train, dataset_eval = dataset_train_eval.split(\n",
        "    split_ratio=1.0 - 1475/5901)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glL3ZO0hEmR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3e5d0b-e010-4488-cd58-9f864dd83461"
      },
      "source": [
        "print(dataset_train.__len__())#4426\n",
        "print(dataset_eval.__len__())#1475\n",
        "print(dataset_test.__len__())#1475"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4426\n",
            "1475\n",
            "1475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__hm9DfEmOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0d1d38-d0b7-49be-9721-582771e2ffea"
      },
      "source": [
        "item = next(iter(dataset_train))\n",
        "print(item.Text)\n",
        "print('長さ : ',len(item.Text) )\n",
        "print('ラベル：',item.Label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    2,  8198,   324,  4617,   768,  2121,  2481,    95,    12,     9,\n",
            "            6,  6381,  3805,  5559, 28557,  7837,    93, 28472, 26003,  3012,\n",
            "        12065,     7,  3104,    12,  2220,     6,   285,   176, 20484,    11,\n",
            "         5625,    10, 21584,  1552, 14025,     8,  3325,     5,  1420,     9,\n",
            "           59,  6262,    11,  2203,  1903,  1964,  2203,  8192,  1964,    13,\n",
            "         6666,     6,  4818,    13,    15,    10,     8,  3712,    36, 10848,\n",
            "        28472,  1710,  3964,    38,    23,   965,    32,   333,   155,    24,\n",
            "           12,     9,     6,   486, 19398,     5,  5017,  2707,     6, 14758,\n",
            "         4942,    60,    14,   608,     5, 20458,    11,  1449,    10,     8,\n",
            "           36,  6122,     9,   151, 29217,  1552, 14025,    14,   109,   308,\n",
            "           10,     8,  6788, 20252,     5,    80,  1738,  2764, 26985,    10,\n",
            "         6172,  9366,  3415,     8, 17957,     6,  7477,   687,   918,     7,\n",
            "         3083,  3051, 28547,   312,     6,  7913,     9, 22752,    10,    13,\n",
            "         7105,     8,   274,    18,   735,  2992, 11218,     6,  1725,     9,\n",
            "        10150,  5345,    18, 14980,    12,    28,    52,   797,     9,    15,\n",
            "         2610,    54,     8, 17957,     6,    70,    72,     7,  3248,    16,\n",
            "         7613,    16,     6,  2459,  2021, 28882, 28468,    16,  5408,    16,\n",
            "         9182,     8,    12,     6,  8849,  2230,  8192,     7,    58,    10,\n",
            "           13,  7105,  1058,  2992,    54,     8,  6165, 11216,    13,  9101,\n",
            "         6172,  9366,     5,    28,     6,  3010,    11,  2589, 28468,    16,\n",
            "           21,    10, 11218,     6,  5559, 28557,  7837,    93,     9,     6,\n",
            "         1552, 14025,    14,  3722, 12730,  6172, 19129,    13,     6,  3722,\n",
            "        12730, 25661,  6172, 19129,  3133,     8,   218,    14,  3028,    14,\n",
            "         9280,  1058,    75,    54,  1852,     8,  9588,    26,    20,    16,\n",
            "           28,     6,  9588,     5,   109,    40, 10227,    11,  1901,    16,\n",
            "         2501,    40,     6, 18124,  8192,     7,    58,    10,    13,  7105,\n",
            "            8,  3028,    11, 22724,   140,   967,    12,     9,     8,    23,\n",
            "        24098,     9,    24,  2787,    28,  2575,  1903,    12,     6, 24098,\n",
            "           11,   704,     7,    15,    16,    21,    10, 11218,     6,   372,\n",
            "        16577,    12,   197,   416,  1133,   126,   151, 29217,   704,     7,\n",
            "          191,   255,     7,  5408,    10,  6172,   625,     5,     9, 26527,\n",
            "        28449,  1761,    38,     8,  1018,  8085,  2707,     7, 15919,    15,\n",
            "           10, 14758,    28,     6,    36, 13961,   408,     5,    72,     9,\n",
            "         6730,    40,  5719,    16,  4831,    10, 11218,     6,   147,  2868,\n",
            "            9,  1552, 14025,   408,     5,   691,    11, 18419,  3054,     6,\n",
            "        18124,  6877,    11,  1330,    16,  3913,    10,    54,  1852,     8,\n",
            "        13162,   324,     7,   861,    13,     6,   691,   687,  4847,   332,\n",
            "           16,     6, 15073,     5,  2575,   408,    14, 15890,    33,    40,\n",
            "            6,  2575,  8192,     7,   297,  3913,    10,    54,  1852,    38,\n",
            "           13,  8615,     5,   308,    10,     8,     3])\n",
            "長さ :  397\n",
            "ラベル： 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8GkKCNEmLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ba987256-02c6-433b-a2b3-c75d9ccba2ca"
      },
      "source": [
        "# datasetの中身を文章に戻して確認\n",
        "print(tokenizer.convert_ids_to_tokens(item.Text.tolist()))#文章\n",
        "dic_id2cat[int(item.Label)]#id\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'WBC', '世界', 'フライ', '級', '王座', '統一', '戦', 'で', 'は', '、', '暫定', '王者', 'ポン', '##サ', '##クレ', '##ック', '##・', '##ウォン', '##ジョン', '##カム', 'に', '判定', 'で', '敗れ', '、', 'プロ', '初', '黒星', 'を', '喫し', 'た', '亀田', '興', '毅', '。', '周囲', 'の', '評価', 'は', 'その', '敗戦', 'を', '“', '経験', '”', '“', '勉強', '”', 'と', '語り', '、', 'よし', 'と', 'し', 'た', '。', 'TBS', '「', 'サンデー', '##・', '##ジャ', '##ポン', '」', '(', '28', '日', '放送', '分', ')', 'で', 'は', '、', '番組', 'コメンテーター', 'の', '高橋', 'ジョージ', '、', 'テリー', '伊藤', 'ら', 'が', '試合', 'の', '感想', 'を', '述べ', 'た', '。', '「', 'スピード', 'は', '全', '##然', '興', '毅', 'が', '上', 'だっ', 'た', '。', '引っ', '##掛かり', 'の', 'ない', 'まま', '終わっ', 'ちゃっ', 'た', 'って', '##いう', '感じ', '。', 'だから', '、', '結論', 'だけ', '最初', 'に', '言っ', 'ちゃ', '##え', 'ば', '、', '俺', 'は', 'よかっ', 'た', 'と', '思う', '。', '変', 'な', '話', 'です', 'けど', '、', 'いずれ', 'は', 'どんな', 'ビッグ', 'な', 'ファイター', 'で', 'も', '一', '敗', 'は', 'し', 'ます', 'よ', '。', 'だから', '、', 'この', '時', 'に', '負け', 'て', 'おい', 'て', '、', 'すぐ', '立ち', '##直', '##っ', 'て', 'やっ', 'て', 'ほしい', '。', 'で', '、', 'いろ', '##んな', '勉強', 'に', 'なっ', 'た', 'と', '思う', 'ん', 'です', 'よ', '。', 'サウス', '##ポー', 'と', 'やる', 'って', '##いう', 'の', 'も', '、', '対策', 'を', '練', '##っ', 'て', 'い', 'た', 'けど', '、', 'ポン', '##サ', '##クレ', '##ック', 'は', '、', '興', '毅', 'が', 'ワン', '##ツー', 'って', 'やってくる', 'と', '、', 'ワン', '##ツー', '##スリー', 'って', 'やってくる', 'わけ', '。', 'それ', 'が', 'ポイント', 'が', '上がる', 'ん', 'だ', 'よ', 'ね', '。', 'ガード', 'さ', 'れ', 'て', 'も', '、', 'ガード', 'の', '上', 'から', 'パンチ', 'を', '入れ', 'て', 'くる', 'から', '、', 'そういう', '勉強', 'に', 'なっ', 'た', 'と', '思う', '。', 'ポイント', 'を', '稼ぐ', 'という', '意味', 'で', 'は', '。', '(', 'バッティング', 'は', ')', 'あれ', 'も', 'いい', '経験', 'で', '、', 'バッティング', 'を', '気', 'に', 'し', 'て', 'い', 'た', 'けど', '、', '天', '晴れ', 'で', '12', 'R', '最後', 'まで', '全', '##然', '気', 'に', 'せ', 'ず', 'に', 'やっ', 'た', 'って', 'いう', 'の', 'は', '褒め', '##る', 'べき', '」', '。', 'こう', '語る', 'ジョージ', 'に', '同調', 'し', 'た', 'テリー', 'も', '、', '「', '内藤', '選手', 'の', '時', 'は', '正面', 'から', '戦っ', 'て', 'くれ', 'た', 'けど', '、', '新', 'チャンピオン', 'は', '興', '毅', '選手', 'の', '力', 'を', '押さえ', '##込む', '、', 'そういう', '才能', 'を', '持っ', 'て', 'まし', 'た', 'よ', 'ね', '。', 'これから', '世界', 'に', 'いく', 'と', '、', '力', 'だけ', 'じゃ', 'なく', 'て', '、', 'テクニック', 'の', 'いい', '選手', 'が', 'いっぱい', 'いる', 'から', '、', 'いい', '勉強', 'に', 'なり', 'まし', 'た', 'よ', 'ね', '」', 'と', '話す', 'の', 'だっ', 'た', '。', '[SEP]']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sports-watch'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gig9Y8zoEmIM"
      },
      "source": [
        "# DataLoader作成（torchtextの文脈⇒⇒iterater）\n",
        "\n",
        "batch_size = 16 # 16,32推奨\n",
        "\n",
        "dl_train =data.Iterator(\n",
        "    dataset_train, batch_size = batch_size,train =True)\n",
        "\n",
        "dl_eval = data.Iterator(\n",
        "    dataset_eval, batch_size = batch_size , train = False, sort = False)\n",
        "\n",
        "dl_test = data.Iterator(\n",
        "    dataset_test, batch_size = batch_size , train = False, sort = False)\n",
        "\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {'train':dl_train, 'val':dl_eval}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtKrDbW8EmEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e51b2f7-43b9-40ae-9b59-c111124260a8"
      },
      "source": [
        "batch = next(iter(dl_test))\n",
        "print(batch)\n",
        "print(batch.Text[0].shape)\n",
        "print(batch.Label.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 16]\n",
            "\t[.Text]:('[torch.LongTensor of size 16x512]', '[torch.LongTensor of size 16]')\n",
            "\t[.Label]:[torch.LongTensor of size 16]\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84-ipQpuB5si"
      },
      "source": [
        "from transformers.modeling_bert import BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm1S9x9vHUQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11248282-1e6e-454b-9977-59fb5975c1ea"
      },
      "source": [
        "# BERTの日本語学習済みパラメータのモデルです\n",
        "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks6MEtBtHjma"
      },
      "source": [
        "# このベースの日本語BERTモデルに、入力が768次元、出力が9クラスの全結合層を用意。\n",
        "# 順伝搬のforward関数を用意します。\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class BertForLivedoor(nn.Module):\n",
        "    '''BERTモデルにLivedoorニュースの9クラスを判定する部分をつなげたモデル'''\n",
        "    def __init__(self):\n",
        "        super(BertForLivedoor, self).__init__()\n",
        "\n",
        "        # BERTモジュール\n",
        "        self.bert = model# 日本語学習済みのBERTモデル\n",
        "        # headにクラス予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元768、出力は9クラス\n",
        "        self.cls = nn.Linear(in_features=768, out_features=9)\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight,std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self,input_ids):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        '''\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "\n",
        "        result = self.bert(input_ids)# reult は、sequence_output, pooled_output\n",
        "        # sequence_outputの先頭の単語ベクトルを抜き出す\n",
        "        vec_0 = result[0]# 最初の0がsequence_outputを示す\n",
        "        vec_0 = vec_0[:,0,:]# 全バッチ。先頭0番目の単語の全768要素\n",
        "        vec_0 = vec_0.view(-1, 768)# sizeを[batch_size, hidden_size]に変換\n",
        "        output = self.cls(vec_0) # 全結合層\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzR0KiTJMoKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0a10a7-150f-49a3-f579-061833b55eac"
      },
      "source": [
        "# モデル構築\n",
        "net = BertForLivedoor()\n",
        "\n",
        "#訓練用モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ネットワーク設定完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IgcDaCKNFkj"
      },
      "source": [
        "# ファインチューニング\n",
        "# BERTのself-Attentionの繰り返し12層のうちの、最後の層のみをパラメータ学習させる設定\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for param in net.parameters():\n",
        "    param.requires_grad=False\n",
        "# 2. BertLayerモジュールの最後の層のみ勾配計算ありに変更\n",
        "for param in net.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for param in net.cls.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB5JJyDkNFf8"
      },
      "source": [
        "# 最適化関数(Adam)\n",
        "import torch.optim as optim\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "        {'params':net.bert.encoder.layer[-1].parameters(),'lr':5e-5},\n",
        "        {'params':net.cls.parameters(),'lr':1e-4}\n",
        "])\n",
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wOT4ijaNFZp"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(),  acc))\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8pB2Tx0NFTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86c0c76-86ba-4806-d0ac-a20a46528ae3"
      },
      "source": [
        "# num_epochs = 1\n",
        "# net_trained = train_model(net, dataloaders_dict,\n",
        "#                           criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "イテレーション 10 || Loss: 0.7048 || 10iter. || 本イテレーションの正解率：0.75\n",
            "イテレーション 20 || Loss: 1.1246 || 10iter. || 本イテレーションの正解率：0.625\n",
            "イテレーション 30 || Loss: 0.4805 || 10iter. || 本イテレーションの正解率：0.75\n",
            "イテレーション 40 || Loss: 0.5414 || 10iter. || 本イテレーションの正解率：0.75\n",
            "イテレーション 50 || Loss: 0.5317 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 60 || Loss: 0.6892 || 10iter. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 70 || Loss: 0.6289 || 10iter. || 本イテレーションの正解率：0.6875\n",
            "イテレーション 80 || Loss: 0.5640 || 10iter. || 本イテレーションの正解率：0.6875\n",
            "イテレーション 90 || Loss: 0.8566 || 10iter. || 本イテレーションの正解率：0.625\n",
            "イテレーション 100 || Loss: 0.3890 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 110 || Loss: 0.5582 || 10iter. || 本イテレーションの正解率：0.75\n",
            "イテレーション 120 || Loss: 0.4103 || 10iter. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 130 || Loss: 0.6775 || 10iter. || 本イテレーションの正解率：0.6875\n",
            "イテレーション 140 || Loss: 0.5574 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 150 || Loss: 0.5359 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 160 || Loss: 0.7830 || 10iter. || 本イテレーションの正解率：0.75\n",
            "イテレーション 170 || Loss: 0.2538 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 180 || Loss: 0.6817 || 10iter. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 190 || Loss: 0.0946 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 200 || Loss: 0.2758 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 210 || Loss: 0.4731 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 220 || Loss: 0.1977 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 230 || Loss: 0.3293 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 240 || Loss: 0.5505 || 10iter. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 250 || Loss: 0.2109 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 260 || Loss: 0.3798 || 10iter. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 270 || Loss: 0.2183 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "Epoch 1/1 | train |  Loss: 0.4782 Acc: 0.8416\n",
            "Epoch 1/1 |  val  |  Loss: 0.3696 Acc: 0.8820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnUy-Qz2UQVT",
        "outputId": "be1fc27e-d72b-469d-d860-b7ef39803e8b"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net_trained.eval()\n",
        "net_trained.to(device)\n",
        "\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in tqdm(dl_test):\n",
        "    inputs = batch.Text[0].to(device)\n",
        "    labels = batch.Label.to(device)\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        outputs = net_trained(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(dl_test.dataset)\n",
        "\n",
        "print(f'テストデータ{len(dl_test.dataset)}個での正解率 : {epoch_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [01:38<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テストデータ1475個での正解率 : 0.8841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToG4bP4lab2x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}