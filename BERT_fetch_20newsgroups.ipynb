{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasune613/hello-world/blob/main/BERT_fetch_20newsgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "r8XaYAwkqhfU"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = fetch_20newsgroups()\n",
        "# dir(data)\n",
        "train_data = fetch_20newsgroups(subset = 'train')\n",
        "valid_data = fetch_20newsgroups(subset = 'test')\n"
      ],
      "metadata": {
        "id": "qgfeZcAWtqKr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOUdg3-RqhiS",
        "outputId": "932c40e2-e5b6-4188-ffa8-207048f74595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DESCR', 'data', 'filenames', 'target', 'target_names']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "dir(train_data)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "cmDSAS8Gqhln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d05bda2f-68f0-4b23-e023-dcf8fb5911b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11314, 2) (7532, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a25b6e26-a549-40ee-87db-e93ca9a94614\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a25b6e26-a549-40ee-87db-e93ca9a94614')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a25b6e26-a549-40ee-87db-e93ca9a94614 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a25b6e26-a549-40ee-87db-e93ca9a94614');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "train = pd.DataFrame({'text' : train_data.data, 'target' : train_data.target})\n",
        "valid = pd.DataFrame({'text' : valid_data.data, 'target' : valid_data.target})\n",
        "print(train.shape, valid.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "kKaSBdrlqhow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "40d88aea-ec98-4043-c387-562c976fc683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "text = train.text.values[0]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "LvbqdWi1qhre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865ef2d7-2c3d-4b53-e9d6-02db7c4fd29d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "target = train.target.values[0]\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "GKc13NJrqhux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680c0e08-d5b6-488c-f70a-0125d38f9031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "rec.autos\n"
          ]
        }
      ],
      "source": [
        "print(train_data.target_names)\n",
        "print(train_data.target_names[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ZLjs-Ovhqhx7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "8e7725df-abae-4cda-b90d-7e32dfe1433d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "text #train.text.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "MQLBzxSSqh0o"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleaning(text):\n",
        "    text = re.sub('\\n',' ',text) \n",
        "    text = re.sub('[^A-Za-z0-9]', ' ', text)\n",
        "    text = re.sub('[\" \"]', ' ',text)\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "cc0V6z5Qqh69"
      },
      "outputs": [],
      "source": [
        "train['cleaning_text']  = train.text.map(cleaning)\n",
        "valid['cleaning_text']  = valid.text.map(cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9MGj9Demqh99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "e3d0ca76-947d-48d0-ee91-ccc405916471"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from  lerxst wam umd edu  where s my thing  subject  what car is this   nntp posting host  rac3 wam umd edu organization  university of maryland  college park lines  15   i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a 2 door sports car  looked to be from the late 60s  early 70s  it was called a bricklin  the doors were really small  in addition  the front bumper was separate from the rest of the body  this is  all i know  if anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail   thanks    il         brought to you by your neighborhood lerxst          '"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "train['cleaning_text'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "zRQaTV5sqiHe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "NR1rZK6oqiKD"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data['cleaning_text'][idx]\n",
        "        label =  self.data['target'][idx]\n",
        "        return text, torch.tensor(label, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "-wD_tZdvqiNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a60def-ad32-4013-cde2-46e5037f9455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('from  lerxst wam umd edu  where s my thing  subject  what car is this   nntp posting host  rac3 wam umd edu organization  university of maryland  college park lines  15   i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a 2 door sports car  looked to be from the late 60s  early 70s  it was called a bricklin  the doors were really small  in addition  the front bumper was separate from the rest of the body  this is  all i know  if anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail   thanks    il         brought to you by your neighborhood lerxst          ', tensor(7.))\n",
            "from  lerxst wam umd edu  where s my thing  subject  what car is this   nntp posting host  rac3 wam umd edu organization  university of maryland  college park lines  15   i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a 2 door sports car  looked to be from the late 60s  early 70s  it was called a bricklin  the doors were really small  in addition  the front bumper was separate from the rest of the body  this is  all i know  if anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail   thanks    il         brought to you by your neighborhood lerxst          \n",
            "tensor(7.)\n"
          ]
        }
      ],
      "source": [
        "ds = Data(train)\n",
        "print(ds[0])\n",
        "print(ds[0][0])\n",
        "print(ds[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "39U3wGQ2qiQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c46d28e-c0a5-4f7e-dc36-571a5879c967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "('from  lerxst wam umd edu  where s my thing  subject  what car is this   nntp posting host  rac3 wam umd edu organization  university of maryland  college park lines  15   i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a 2 door sports car  looked to be from the late 60s  early 70s  it was called a bricklin  the doors were really small  in addition  the front bumper was separate from the rest of the body  this is  all i know  if anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail   thanks    il         brought to you by your neighborhood lerxst          ', 'from  guykuo carson u washington edu  guy kuo  subject  si clock poll   final call summary  final call for si clock reports keywords  si acceleration clock upgrade article i d   shelley 1qvfo9innc3s organization  university of washington lines  11 nntp posting host  carson u washington edu  a fair number of brave souls who upgraded their si clock oscillator have shared their experiences for this poll  please send a brief message detailing your experiences with the procedure  top speed attained  cpu rated speed  add on cards and adapters  heat sinks  hour of usage per day  floppy disk functionality with 800 and 1 4 m floppies are especially requested   i will be summarizing in the next two days  so please add to the network knowledge base if you have done the clock upgrade and haven t answered this poll  thanks   guy kuo  guykuo u washington edu  ', 'from  twillis ec ecn purdue edu  thomas e willis  subject  pb questions    organization  purdue university engineering computer network distribution  usa lines  36  well folks  my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985   sooo  i m in the market for a new machine a bit sooner than i intended to be     i m looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that  hopefully  somebody can answer     does anybody know any dirt on when the next round of powerbook introductions are expected   i d heard the 185c was supposed to make an appearence  this summer  but haven t heard anymore on it   and since i don t have access to macleak  i was wondering if anybody out there had more info       has anybody heard rumors about price drops to the powerbook line like the ones the duo s just went through recently     what s the impression of the display on the 180   i could probably swing a 180 if i got the 80mb disk rather than the 120  but i don t really have a feel for how much  better  the display is  yea  it looks great in the store  but is that all  wow  or is it really that good     could i solicit some opinions of people who use the 160 and 180 day to day on if its worth taking the disk size and money hit to get the active display    i realize this is a real subjective question  but i ve only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful      how well does hellcats perform       thanks a bunch in advance for any info   if you could email  i ll post a summary  news reading time is at a premium with finals just around the corner            tom willis     twillis ecn purdue edu         purdue electrical engineering                                                                              convictions are more dangerous enemies of truth than lies      f  w  nietzsche ', 'from  jgreen amber  joe green  subject  re  weitek p9000   organization  harris computer systems division lines  14 distribution  world nntp posting host  amber ssd csd harris com x newsreader  tin  version 1 1 pl9   robert j c  kyanko  rob rjck uucp  wrote    abraxis iastate edu writes in article  abraxis 734340159 class1 iastate edu       anyone know about the weitek p9000 graphics chip    as far as the low level stuff goes  it looks pretty nice   it s got this   quadrilateral fill command that requires just the four points   do you have weitek s address phone number   i d like to get some information about this chip      joe green    harris corporation jgreen csd harris com   computer systems division  the only thing that really scares me is a person with no sense of humor            jonathan winters ')\n",
            "tensor([7., 4., 4., 1.])\n"
          ]
        }
      ],
      "source": [
        "dl = DataLoader(ds, batch_size = 4)\n",
        "batch = next(iter(dl))\n",
        "print(len(batch))\n",
        "print(batch[0])\n",
        "print(batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "yptSSazAqiUJ"
      },
      "outputs": [],
      "source": [
        "train_ds = Data(train)\n",
        "valid_ds =Data(valid)\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = 32, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = 32*2, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "nakJZRhoqiXk"
      },
      "outputs": [],
      "source": [
        "!pip -q install  transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "-b_NfUAYqiaj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "i9VkGSVYqids",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "e4fab48b-6f94-464d-fe51-3f7eaafd0a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from  lerxst wam umd edu  where s my thing  subject  what car is this   nntp posting host  rac3 wam umd edu organization  university of maryland  college park lines  15   i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a 2 door sports car  looked to be from the late 60s  early 70s  it was called a bricklin  the doors were really small  in addition  the front bumper was separate from the rest of the body  this is  all i know  if anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail   thanks    il         brought to you by your neighborhood lerxst          '"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "text = train['cleaning_text'].values[0]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ZApKUKwXqihB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975e0c0b-7a07-4c34-d1dc-61b35bbadf4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2013, 3393, 2099, 2595, 3367, 11333, 2213, 8529, 2094, 3968, 2226, 2073, 1055, 2026, 2518, 3395, 2054, 2482, 2003, 2023, 1050, 3372, 2361, 14739, 3677, 10958, 2278, 2509, 11333, 2213, 8529, 2094, 3968, 2226, 3029, 2118, 1997, 5374, 2267, 2380, 3210, 2321, 1045, 2001, 6603, 2065, 3087, 2041, 2045, 2071, 4372, 7138, 2368, 2033, 2006, 2023, 2482, 1045, 2387, 1996, 2060, 2154, 2009, 2001, 1037, 1016, 2341, 2998, 2482, 2246, 2000, 2022, 2013, 1996, 2397, 20341, 2220, 17549, 2009, 2001, 2170, 1037, 5318, 4115, 1996, 4303, 2020, 2428, 2235, 1999, 2804, 1996, 2392, 21519, 2001, 3584, 2013, 1996, 2717, 1997, 1996, 2303, 2023, 2003, 2035, 1045, 2113, 2065, 3087, 2064, 2425, 4168, 1037, 2944, 2171, 3194, 28699, 2015, 2086, 1997, 2537, 2073, 2023, 2482, 2003, 2081, 2381, 2030, 3649, 18558, 2017, 2031, 2006, 2023, 24151, 2559, 2482, 3531, 1041, 5653, 4283, 6335, 2716, 2000, 2017, 2011, 2115, 5101, 3393, 2099, 2595, 3367, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "encoded = tokenizer.encode_plus(text)\n",
        "encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYW6e6pHB9Yx",
        "outputId": "e3cb1df1-da44-4c72-8dcb-bdc7cee59409"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIN6tdIOCaGR",
        "outputId": "8c9877ee-1fa8-4378-9fbf-73aae59a50fd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "dQ0-BIYCCmzM"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = []\n",
        "\n",
        "for text in train['cleaning_text'].values:\n",
        "    encoded = tokenizer.encode_plus(text.lower())\n",
        "    length.append(len(encoded['input_ids']))\n",
        "\n",
        "plt.hist(length,color = 'gray')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "HIDj-Y75Cy4h",
        "outputId": "c7c1840e-f5de-4f8d-cf19-5336464f4090"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "length = np.array(length)\n",
        "print(' 中央値 : ', np.quantile(length, q=0.5))\n",
        "print(' 75％ : ', np.quantile(length, q=0.75))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqWCiKylDFT7",
        "outputId": "8f0a6512-f1bc-415d-a37a-c54f27a7d561"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 中央値 :  233.0\n",
            " 75％ :  368.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256\n",
        "encoded = tokenizer.encode_plus(text, padding='max_length', max_length=MAX_LEN,truncation=True)\n",
        "print(len(encoded['input_ids']))\n",
        "print(encoded['attention_mask'][:10])\n",
        "print(encoded['attention_mask'][-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbN2-XsRE25K",
        "outputId": "4cace0cd-0384-4d98-b0dd-793854b8abab"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(encoded['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BrJoRexFzsK",
        "outputId": "7ac8d8b4-8617-40f4-8e00-b367d7a549f5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] from gunning cco caltech edu kevin j gunning subject stolen cbr900rr organization california institute of technology pasadena lines 12 distribution usa nntp posting host alumni caltech edu summary see above stolen from pasadena between 4 30 and 6 30 pm on 4 15 blue and white honda cbr900rr california plate kg cbr serial number jh2sc281xpm100187 engine number 2101240 no turn signals or mirrors lights taped over for track riders session at willow springs tomorrow guess i ll miss it help me find my baby kjg [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "PryhiN1PGfmb"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.classifier = nn.Linear(in_features = 768, out_features = 20)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.bert(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
        "        pooler_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooler_output).squeeze(-1)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "a5y-IO0uHAWx"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deHJr8dCH81T",
        "outputId": "29cc0ee9-94ef-4d67-f4fa-45aa6a634a5f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "EvnmJxaKhyoT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() # 学習モード\n",
        "train_loss = 0\n",
        "for batch in train_dl:\n",
        "    optimizer.zero_grad() \n",
        "    text = batch[0] # 文章\n",
        "    label = batch[1].long().cuda() # 正解ラベル\n",
        "\n",
        "    # tokenizer.batch_encode_plus -> 複数の文を一度に処理したいとき\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        list(text), padding = \"max_length\", max_length = MAX_LEN, truncation = True,\n",
        "        return_tensors = \"pt\", return_attention_mask = True, return_token_type_ids = True\n",
        "        ) # バッチごと変換する。文章はリストに入れる必要あり。\n",
        "\n",
        "    input_ids = encoded[\"input_ids\"].cuda()\n",
        "    attention_mask = encoded[\"attention_mask\"].cuda()\n",
        "    token_type_ids = encoded[\"token_type_ids\"].cuda()\n",
        "    preds = model(input_ids, attention_mask, token_type_ids) # 予測\n",
        "    loss = criterion(preds, label) # 損失計算\n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "    train_loss += loss.item()\n",
        "train_loss /= len(train_dl)\n",
        "print(train_loss)"
      ],
      "metadata": {
        "id": "kqsZxj-vifzx"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "valid_loss = 0\n",
        "with torch.no_grad():\n",
        "    for batch in valid_dl():\n",
        "        text = batch[0]\n",
        "        label = batch[1].long().cuda()\n",
        "        encoded = tokenizer.batch_encod_plus(\n",
        "            list(text), padding='max_length', max_length= MAX_LEN,truncation=True,\n",
        "            return_tensors = 'pt', return_attention_mask = True, return_token_type_ids = True\n",
        "            )\n",
        "        input_ids = encoded['input_ids'].cuda()\n",
        "        attention_mask = encoded['attention_mask'].cuda()\n",
        "        token_type_ids = encoded['token_type_ids'].cuda()\n",
        "        \n",
        "        preds = model(input_ids,attention_mask,token_type_ids)\n",
        "        loss = criterion(preds, label)\n",
        "        valid_loss += loss.item()\n",
        "    valid_loss /= len(valid_dl)\n",
        "\n",
        "print(valid_loss)"
      ],
      "metadata": {
        "id": "Baa2hq3jokHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 実際には繰り返す\n",
        "\n",
        "model = Model()\n",
        "optimizer = toch.optim.Adam(model.parameters(), lr=1e=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_loss = np.inf\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch in train_dl:\n",
        "        text = batch[0]\n",
        "        label = batch[1].long().cuda()\n",
        "        encoded = torch.batch_encode_plus(\n",
        "            list(text), padding='max_length', \n",
        "            max_length=MAX_LEN,truncation=True,return_tensors='pt',\n",
        "            return_mask=True,return_token_type_ids=True\n",
        "        )\n",
        "        input_ids =encoded['input_ids'].cuda()\n",
        "        attention_mask = encoded['attention_mask'].cuda()\n",
        "        token_type_ids = encoded['token_type_ids'].cuda()\n",
        "        preds = model(input_ids, attention_mask,token_type_ids)\n",
        "        loss = criterion(preds, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_dl)\n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dl:\n",
        "            text = batch[0]\n",
        "            label = batch[1].long().cuda()\n",
        "            encoded = torch.batch_encode_plus(\n",
        "                list(text), padding = 'max_length',\n",
        "                max_length = MAX_LEN, truncation=True, return_tensors='pt',\n",
        "                return_mask=True, return_token_type_ids=True\n",
        "            )\n",
        "            input_ids = encoded['input_ids'].cuda()\n",
        "            attention_mask = encoded['attention_mask'].cuda()\n",
        "            token_type_ids = encoded['token_type_ids'].cuda()\n",
        "            preds = model(input_ids, attention_mask, token_type_ids)\n",
        "            loss = criterion(preds, label)\n",
        "            valid_loss += loss.item()\n",
        "        valid_loss /= len(valid_dl)\n",
        "\n",
        "    print(f'EPOCH[{epoch+1}]')\n",
        "    print(train_loss)\n",
        "    print(valid_loss)\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert.pth')\n",
        "        print('saved ...')"
      ],
      "metadata": {
        "id": "UHcosaWXokEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('bert.pth',map_location='cpu'))\n",
        "\n",
        "model.eval()\n",
        "oof = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in valid_dl:\n",
        "        text = batch[0]\n",
        "        encoded = tokenizer.batch_encode_plus(\n",
        "            list(text), padding = 'max_length', max_length=MAX_LEN,\n",
        "            truncation = True,return_tensors = 'pt', \n",
        "            return_attention_mask=True, return_token_type_ids = True)\n",
        "        input_ids = encoded['input_ids'].cuda()\n",
        "        attention_mask = encoded['attention_mask'].cuda()\n",
        "        token_type_ids = encoded['token_type_ids'].cuda()\n",
        "        preds = model(input_ids, attention_mask, token_type_ids)\n",
        "        oof.append(preds.cpu().numpy())# 予測結果を入れる\n",
        "oof = np.concatenate(oof, axis = 0) # 予測結果を１次元にまとめる"
      ],
      "metadata": {
        "id": "kY3P7gJRokBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(oof.argmax(axis = 1)[:20])\n",
        "print('=' *100)\n",
        "print(valid['torget'].values[:20])"
      ],
      "metadata": {
        "id": "NaDMNljMoj-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(valid['target'], oof.argmax(axis = 1))\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "1x4kcuN-oj7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rLa0v5uNoj45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rIf1b_TXoj17"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BERT_fetch_20newsgroups.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbeQgDCON6VTjNXmWi+yMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}